Analyses for the paper: "A 365-Participant Corpus of Eye Movements in L1 and L2 English Reading"

Before running this script please obtain the data as follows:

CELER:
1. Obtain the [PTB-WSJ](https://catalog.ldc.upenn.edu/LDC95T7) and [BLLIP](https://catalog.ldc.upenn.edu/LDC2000T43) corpora through LDC.
2. - Copy the `README` file of the PTB-WSJ (starts with "This is the Penn Treebank Project: Release 2 ...") to the folder `ptb_bllip_readmes/PTB/`. 
   - Copy the `README.1st` file of BLLIP (starts with "File:  README.1st ...") to the folder `ptb_bllip_readmes/BLLIP/`
3. Run `python obtain_data.py` to download `data_2.0.zip`. Extract to the top level of this directory.

GECO:
Download GECO augmented with frequency and surprisal values from the following url and place `geco/` at the top level of this directory
https://drive.google.com/file/d/1T4qgbwPkdzYmTvIqMUGJlvY-v22Ifinx/view?usp=sharing

The script uses Julia MixedModels library. Install Julia here https://julialang.org/downloads/, then open Julia and install the required libraries RCall and MixedModels:
Pkg.add("RCall")
Pkg.add("MixedModels")

```{r}
set.seed(214)

library(tidyverse)
library(lme4)
library(lmerTest)
library(readxl)
library(rjson)
library(lattice)
library(car) #for Levene test
library(JuliaCall)

j<-julia_setup()
j$library("MixedModels")

#Settings for frequency and surprisal. Frequency FREQ_SUBTLEX / FREQ_BLLIP / FREQ_WEB. Surprisal SURP_GPT2 / SURP_LSTM / SURP_KENLM. For GECO, only GPT2 is currently available.
#CELER
FREQ_CELER = "FREQ_SUBTLEX"
OOV_CELER = "OOV_SUBTLEX"
SURP_CELER = "SURP_GPT2"
#GECO
FREQ_GECO = "FREQ_SUBTLEX"
OOV_GECO = "OOV_SUBTLEX"
SURP_GECO = "SURP_GPT2"
```

Load CELER and GECO metadata and Plot basic participant stats
```{r,fig.width=12,fig.height=4}
geco_metadata = read_xlsx("geco/SubjectInformation.xlsx", na = c("", ".")) %>% rename("Age" = "AGE", "English.AoA" =  "AOA_ENG") %>% mutate(English = ifelse(GROUP == "bilingual", "L2", "L1"),
                        L1 = as.factor(ifelse(GROUP == "bilingual", "Dutch", "English")),
                        DATASET = "GECO")

celer_metadata = read.table("participant_metadata/metadata.tsv", header = TRUE, quote = "", sep = "\t") %>% 
                        mutate(English = ifelse(L1 == "English", "L1", "L2"),
                               DATASET = "CELER") %>%
                               column_to_rownames(var="List")

metadata_all = bind_rows(geco_metadata, celer_metadata) %>% mutate_at(c("English", "L1", "DATASET"), as.factor)
metadata_long = gather(metadata_all, "property", "x", c("Age", "English.AoA",  "MichiganLG"), factor_key = TRUE)


property.labs = c("Age", "English Age of Acquisition", "MichiganLG")
names(property.labs) = c("Age", "English.AoA", "MichiganLG")
plot_data = filter(metadata_long, English == "L2")
p <- ggplot() +
      theme_minimal(base_size = 40) +
      geom_histogram(data = plot_data, aes(x = x, fill = DATASET), binwidth = 4, alpha = 0.7) +
      facet_grid(. ~ property, scales = "free", labeller = labeller(property = property.labs)) +
      scale_color_manual(values = c("CELER"="blue", "GECO"="red")) +
      scale_fill_manual(values = c("CELER"="blue", "GECO"="red")) +
      theme(aspect.ratio=1) +
      labs(y = "# ESL Participants",
           x = NULL,
           fill = "Dataset")
    ggsave(file="dataset_analyses_figures/participants.png", p, height=9,width=27)
p
```


```{r}
code_vars <- function(report){
    report$English_01 <- ifelse(report$English == "L2", 1, 0)
    report$English_05 <- ifelse(report$English == "L2", 0.5, -0.5)
    report$DATASET_05 <- ifelse(report$DATASET == "CELER", 0.5, -0.5)
    return(report)
}
```

Load GECO
```{r}
geco_ia_l2 <- read_xlsx("geco/L2ReadingDataAugmented.xlsx", na = c("", ".")) 
geco_ia_l1 <- read_xlsx("geco/MonolingualReadingDataAugmented.xlsx", na = c("", "."))
geco_ia <- bind_rows(geco_ia_l1, geco_ia_l2) %>% 
           mutate(DATASET = as.factor("GECO"),
                  GROUP = as.factor(GROUP),
                  PP_NR = as.factor(PP_NR),
                  WORD_ID = as.factor(WORD_ID),
                  WORD_NORM = as.factor(WORD_NORM),
                  LANGUAGE_RANK = as.factor(LANGUAGE_RANK),
                  FREQ_BLLIP = as.double(FREQ_BLLIP),
                  FREQ_WEB = as.double(FREQ_WEB),
                  FREQ_SUBTLEX = as.double(FREQ_SUBTLEX)) %>% 
           #set default frequency and surprisal
           mutate_("FREQUENCY" = FREQ_GECO, 
                  "OOV" = OOV_GECO,
                  "SURPRISAL" = SURP_GECO) %>%
           rename(SUBJECT = PP_NR,
                  English = LANGUAGE_RANK,
                  FIRST_FIXATION = WORD_FIRST_FIXATION_DURATION,
                  GAZE_DURATION = WORD_GAZE_DURATION,
                  TOTAL_FIXATION = WORD_TOTAL_READING_TIME,
                  AVERAGE_FIX_PUPIL_SIZE = WORD_AVERAGE_FIX_PUPIL_SIZE,
                  FIXATION_COUNT = WORD_FIXATION_COUNT) %>% #SKIP = WORD_SKIP 
           mutate(# previous word properties
                  SURPRISAL_prev1 = lag(SURPRISAL),
                  FREQUENCY_prev1 = lag(FREQUENCY),
                  WORD_LEN_prev1 = lag(WORD_LEN),
                  OOV_prev1 = lag(OOV),
                  WORD_NORM_prev1 = lag(WORD_NORM),
                  WORD_ID_prev1 = lag(WORD_ID),
                  # Note: for some reason skipped words TOTAL FIXATION is sometimes NaN and sometimes 0
                  TOTAL_FIXATION = na_if(TOTAL_FIXATION, 0),
                  # Note: default WORD_SKIP in GECO is for first pass
                  SKIP = ifelse(is.na(TOTAL_FIXATION),1,0),
                  # all GECO participants read the same text
                  shared_text = 1) %>% 
          code_vars
geco_ia_long <- gather(geco_ia, "fix_measure", "RT", 
                    c('FIRST_FIXATION', 'GAZE_DURATION', 'TOTAL_FIXATION', 'SKIP', 'FIXATION_COUNT'), factor_key = TRUE) 
```


Load CELER Interest area report
```{r}
#Load interest area report
celer_ia <- read.table("data_v2.0/sent_ia.tsv", header = TRUE, quote = "", sep = "\t", na.strings = c("", ".")) 

celer_ia <- celer_ia %>%
                 rename(SUBJECT = list,
                        TRIAL = trial,
                        FIRST_FIXATION = IA_FIRST_FIXATION_DURATION,
                        GAZE_DURATION = IA_FIRST_RUN_DWELL_TIME,
                        TOTAL_FIXATION = IA_DWELL_TIME,
                        SKIP = IA_SKIP,
                        FIXATION_COUNT = IA_FIXATION_COUNT,
                        WORD = IA_LABEL) %>%
                 # set default frequency and suprisal
                 mutate_("FREQUENCY" = FREQ_CELER, 
                        "OOV" = OOV_CELER,
                        "SURPRISAL" = SURP_CELER) %>%
                 mutate(DATASET = as.factor("CELER"),
                        FREQ_BLLIP = as.double(FREQ_BLLIP),
                        FREQ_WEB = as.double(FREQ_WEB),
                        FREQ_SUBTLEX = as.double(FREQ_SUBTLEX),
                        SUBJECT = as.factor(SUBJECT),
                        WORD_ID = as.factor(paste(TRIAL, IA_ID, sep = "_")), #meaninful only for the shared regime
                        WORD_NORM = as.factor(WORD_NORM),    
                        WORD = as.character(WORD),
                        # set Total Fixation to be undefined for skipped words
                        TOTAL_FIXATION = na_if(TOTAL_FIXATION, 0),
                        # previous word properties
                        SURPRISAL_prev1 = lag(SURPRISAL),
                        FREQUENCY_prev1 = lag(FREQUENCY),
                        WORD_LEN_prev1 = lag(WORD_LEN),
                        OOV_prev1 = lag(OOV),
                        WORD_NORM_prev1 = lag(WORD_NORM),
                        WORD_ID_prev1 = lag(WORD_ID)) %>%
                # add L1 and proficiency information form metadata
                 mutate(MPT = map_dbl(SUBJECT, function(x){celer_metadata[toString(x),"MichiganLG"]}),
                        L1 = unlist(map(SUBJECT, function(x){celer_metadata[toString(x),"L1"]})),
                        English = as.factor(ifelse(L1 == "English", "L1", "L2"))) %>% 
                 code_vars

celer_ia_long <- gather(celer_ia, "fix_measure", "RT", 
                        c('FIRST_FIXATION', 'GAZE_DURATION', 'TOTAL_FIXATION', "SKIP", "FIXATION_COUNT"), factor_key = TRUE) 

#compute approximate number of characters per visual angle
n_upper <- sum(str_count(celer_ia$WORD, "[A-Z]"), na.rm = TRUE)
n_all_char <- sum(nchar(celer_ia$WORD), na.rm = TRUE)
n_lower <- n_all_char - n_upper

#0.36 degrees for lowercase letter, 0.49 for uppercase
mean_char_visual_degrees = 0.36*(n_lower/n_all_char)+0.49*(n_upper/n_all_char) 
CHARS_PER_ANGLE = 1/mean_char_visual_degrees
```


Load CELER Fixation report
```{r}
#Load Fixation report
celer_fix <- read.table("data_v2.0/sent_fix.tsv", header = TRUE, quote = "", sep = "\t", stringsAsFactors = FALSE) 

celer_fix <- celer_fix %>%
                  rename(SUBJECT = list,
                         TRIAL = trial) %>%
                  # filter out saccades to and from locations that are outside the text area
                  filter(NEXT_SAC_AMPLITUDE != '.', 
                         CURRENT_FIX_INTEREST_AREA_ID != '.') %>% 
                  # set default frequency and suprisal
                  mutate_("FREQUENCY" = FREQ_CELER, 
                        "OOV" = OOV_CELER,
                        "SURPRISAL" = SURP_CELER) %>%
                  mutate(DATASET = as.factor("CELER"),
                         SUBJECT = as.factor(SUBJECT),
                         WORD_ID = as.factor(paste(TRIAL, CURRENT_FIX_INTEREST_AREA_ID, sep = "_")),
                         WORD_NORM = as.factor(WORD_NORM),
                         NEXT_SAC_AMPLITUDE = as.double(NEXT_SAC_AMPLITUDE)*CHARS_PER_ANGLE,
                         NEXT_SAC_AVG_VELOCITY = as.double(NEXT_SAC_AVG_VELOCITY)*CHARS_PER_ANGLE,
                         # previous word properties
                         SURPRISAL_prev1 = lag(SURPRISAL),
                         FREQUENCY_prev1 = lag(FREQUENCY),
                         WORD_LEN_prev1 = lag(WORD_LEN),
                         OOV_prev1 = lag(OOV),
                         WORD_NORM_prev1 = lag(WORD_NORM),
                         WORD_ID_prev1 = lag(WORD_ID),
                         REGRESSION = ifelse(NEXT_SAC_DIRECTION == "LEFT", 1, 0)) %>%
                  # add L1 and proficiency information form metadata
                  mutate(MPT = map_dbl(SUBJECT, function(x){celer_metadata[toString(x),"MichiganLG"]}),
                         L1 = unlist(map(SUBJECT, function(x){celer_metadata[toString(x),"L1"]})),
                         English = as.factor(ifelse(L1 == "English", "L1", "L2"))) %>% 
                  code_vars

celer_fix_long <- gather(celer_fix, "fix_measure", "RT", 
                         c("CURRENT_FIX_DURATION", "NEXT_SAC_AMPLITUDE", "NEXT_SAC_AVG_VELOCITY", "REGRESSION"), factor_key = TRUE) 
```
TODO?: can also filter NEXT_FIX_INTEREST_AREA_ID != '.' to exclude saccades that go outside the text region

Preprocess data
```{r}
filter_words <- function(df){
      df_filtered <- df %>% group_by(SUBJECT, TRIAL) %>% 
                            slice(2:(n()-1)) %>% ungroup() %>% #first and last words
                            filter(!grepl("NUM", WORD_NORM), #numbers
                                   !grepl('^[[:punct:]]|[[:punct:]]$', WORD), #words with punctuation
                                   OOV == 0, OOV_prev1 == 0, #out of vocabulary words
                                   !is.na(TOTAL_FIXATION)) #skips

  return(df_filtered)
}


center_predictors <- function(df){
  df_centered <- df %>% mutate(FREQUENCY_c = FREQUENCY - mean(FREQUENCY), 
                               SURPRISAL_c = SURPRISAL - mean(SURPRISAL), 
                               WORD_LEN_c = WORD_LEN- mean(WORD_LEN),
                               FREQUENCY_prev1_c = FREQUENCY_prev1 - mean(FREQUENCY_prev1), 
                               SURPRISAL_prev1_c = SURPRISAL_prev1 - mean(SURPRISAL_prev1), 
                               WORD_LEN_prev1_c = WORD_LEN_prev1- mean(WORD_LEN_prev1)) 
  return(df_centered)
}

celer_ia_oov <- celer_ia %>% filter_words %>% center_predictors %>% ungroup() #group_by(shared_text) %>%
celer_ia_oov_long <- gather(celer_ia_oov, "fix_measure", "RT", 
                            c("FIRST_FIXATION", "GAZE_DURATION", "TOTAL_FIXATION"))
geco_ia_oov <- geco_ia %>% filter_words %>% center_predictors
geco_ia_oov_long <- gather(geco_ia_oov, "fix_measure", "RT", 
                        c("FIRST_FIXATION", "GAZE_DURATION", "TOTAL_FIXATION"))
```

Table 3: the effects of frequency, surprisal and word length on reading times (First Fixation, Gaze Duration, Total fixation)

Mixed Effects models in Julia
```{r}
run_mixed_effects_julia <- function(report, mx_formula){
    julia_assign("report", report)
    julia_assign("formula", formula(mx_formula))
    result <- julia_eval("fit(LinearMixedModel, formula, report)")
    return(result)
}
```

Frequency, Suprisal and Word length effects
```{r}
formula1 = "RT ~ FREQUENCY_c + FREQUENCY_prev1_c +
                 SURPRISAL_c + SURPRISAL_prev1_c + 
                 WORD_LEN_c + WORD_LEN_prev1_c + 
                 (FREQUENCY_c + FREQUENCY_prev1_c + SURPRISAL_c + SURPRISAL_prev1_c + WORD_LEN_c + WORD_LEN_prev1_c | SUBJECT)" # (SURPRISAL_c|WORD_NORM)
formula2 = "RT ~ English_05*FREQUENCY_c + English_05*FREQUENCY_prev1_c + 
                 English_05*SURPRISAL_c + English_05*SURPRISAL_prev1_c + 
                 English_05*WORD_LEN_c + English_05*WORD_LEN_prev1_c + 
                 (FREQUENCY_c + FREQUENCY_prev1_c + SURPRISAL_c + SURPRISAL_prev1_c + WORD_LEN_c + WORD_LEN_prev1_c | SUBJECT)" # (English*SURPRISAL_c|WORD_NORM)
```

GECO by English
```{r}
for (L in c("L1", "L2")){ 
    for (measure in c("FIRST_FIXATION", "GAZE_DURATION", "TOTAL_FIXATION")){
      print(L)
      print(measure)
      cat("GECO\n")
      print(run_mixed_effects_julia(filter(geco_ia_oov_long, fix_measure == measure, English == L), formula1))
      cat("\n")
    }
}
```

GECO Compare L1 and L2
```{r}
for (measure in c("FIRST_FIXATION", "GAZE_DURATION", "TOTAL_FIXATION")){
    print(measure)
    cat("CELER\n")
    print(run_mixed_effects_julia(filter(geco_ia_oov_long, fix_measure == measure), formula2))
    cat("\n")
}
```

CELER by English
```{r}

for (L in c("L1", "L2")){
    for (measure in c("FIRST_FIXATION", "GAZE_DURATION", "TOTAL_FIXATION")){
      print(L)
      print(measure)
        cat("CELER\n")
        print(run_mixed_effects_julia(filter(celer_ia_oov_long, fix_measure == measure, English == L), formula1))
        cat("\n")
    }
}
```

CELER Compare L1 and L2
```{r}
for (measure in c("FIRST_FIXATION", "GAZE_DURATION", "TOTAL_FIXATION")){
      print(measure)
      cat("GECO\n")
      print(run_mixed_effects_julia(filter(celer_ia_oov_long, fix_measure == measure), formula2))
      cat("\n")
    }
```

Compare CELER and GECO
```{r}
report_all = bind_rows(geco_ia_oov_long, celer_ia_oov_long)

      formula3 = "RT ~ DATASET_05*English_05*FREQUENCY_c + DATASET_05*English_05*FREQUENCY_prev1_c + 
                       DATASET_05*English_05*SURPRISAL_c + DATASET_05*English_05*SURPRISAL_prev1_c + 
                       DATASET_05*English_05*WORD_LEN_c + DATASET_05*English_05*WORD_LEN_prev1_c + 
                       (FREQUENCY_c + FREQUENCY_prev1_c + SURPRISAL_c + SURPRISAL_prev1_c + WORD_LEN_c + WORD_LEN_prev1_c | SUBJECT)"
      formula4 = "RT ~ DATASET_05*FREQUENCY_c + DATASET_05*FREQUENCY_prev1_c + 
                       DATASET_05*SURPRISAL_c + DATASET_05*SURPRISAL_prev1_c + 
                       DATASET_05*WORD_LEN_c + DATASET_05*WORD_LEN_prev1_c + 
                       (FREQUENCY_c + FREQUENCY_prev1_c + SURPRISAL_c + SURPRISAL_prev1_c + WORD_LEN_c + WORD_LEN_prev1_c | SUBJECT)"

for (measure in c("FIRST_FIXATION", "GAZE_DURATION", "TOTAL_FIXATION")){
      print(measure)
      #cat("CELER vs GECO\n")
      #print(run_mixed_effects_julia(filter(report_all, fix_measure == measure), formula3))
      #cat("\n")
      cat("CELER vs GECO L1\n")
      print(run_mixed_effects_julia(filter(report_all, fix_measure == measure, English =="L1"), formula4))
      cat("\n")
      print(measure)
      cat("CELER vs GECO L2\n")
      print(run_mixed_effects_julia(filter(report_all, fix_measure == measure, English =="L2"), formula4))
      cat("\n")
}
      
for (measure in c("FIRST_FIXATION", "GAZE_DURATION", "TOTAL_FIXATION")){
      print(measure)
      cat("CELER vs GECO\n")
      print(run_mixed_effects_julia(filter(report_all, fix_measure == measure), formula3))
      cat("\n")
}
```



Table 2: Benchmarks for standard fixation measures for L1 and L2 on CELER and GECO
```{r}
#L1 and L2 means
mean_lmer <- function(report){
  shared_text = unique(report$shared_text)
  dataset = unique(report$DATASET)
  print(paste(dataset, unique(report$fix_measure), unique(report$English)))
  se = as_tibble(coef(summary(lmer(RT ~ 1 + (1 |SUBJECT), #+ (1|WORD_ID) 
                                     control=lmerControl(optimizer = "bobyqa", calc.derivs = FALSE), data = report))))
  se <- se %>% mutate(CI = `Std. Error`*1.96)
  return(se)    
}

#L1 vs L2 difference
run_lmer <- function(report){
  shared_text = unique(report$shared_text)
  measure = unique(report$fix_measure)
  dataset = unique(report$DATASET)
  if ((measure == "SKIP")|(measure == "REGRESSION")){
      print(paste("MODEL logistic", dataset, measure))
      m <- glmer(RT ~ English_01 + (1 |SUBJECT), family = binomial(),
                      control=lmerControl(optimizer = "bobyqa", calc.derivs = FALSE), data=report)
  } else if (measure == "FIXATION_COUNT"){
      print(paste("MODEL poisson", dataset, measure))
      m <- glmer(RT ~ English_01 + (1 |SUBJECT), family = poisson(),
                      control=lmerControl(optimizer = "bobyqa", calc.derivs = FALSE), data=report)
  }
  else {
      print(paste("MODEL regression", dataset, measure))
      m <- lmer(RT ~ English_01 + (1 |SUBJECT), 
                     control=lmerControl(optimizer = "bobyqa", calc.derivs = FALSE), data=report)
    }
  fixed_effects <- data.frame(summary(m)$coefficients)
  return(fixed_effects)
}

#L1/L2 -- CELER/GECO interaction
run_lmer_geco_celer_interaction <- function(report){
  measure = unique(report$fix_measure)
  if ((measure == "SKIP")|(measure == "REGRESSION")){
      print(paste("MODEL logistic", measure))
      m <- glmer(RT ~ English_05*DATASET_05 + (1 |SUBJECT), family = binomial(), control=glmerControl(optimizer = "bobyqa", calc.derivs = FALSE), data=report)
  } else if (measure == "FIXATION_COUNT"){
      print(paste("MODEL poisson", measure))
      m <- glmer(RT ~ English_05*DATASET_05 + (1 |SUBJECT), family = poisson(), control=glmerControl(optimizer = "bobyqa", calc.derivs = FALSE), data=report)
    }
  else{
      print(paste("MODEL regression", measure))
      m <- lmer(RT ~ English_05*DATASET_05 + (1 |SUBJECT), control=lmerControl(optimizer = "bobyqa", calc.derivs = FALSE), data=report)
    }
  fixed_effects <- data.frame(cbind(Coef = rownames(summary(m)$coefficients), summary(m)$coefficients))
  return(fixed_effects)
}
```


```{r}
means_ia_celer <- celer_ia_long %>% group_by(fix_measure, English) %>% do(mean_lmer(.))
tests_ia_celer <- celer_ia_long %>% group_by(fix_measure) %>% do(run_lmer(.))
```

```{r}
means_ia_celer  %>% mutate_if(is.numeric, round, digits=5)
tests_ia_celer  %>% mutate_if(is.numeric, round, digits=5)
```

```{r}
means_ia_geco <- geco_ia_long %>% group_by(fix_measure, English) %>% do(mean_lmer(.))
tests_ia_geco <- geco_ia_long %>% group_by(fix_measure) %>% do(run_lmer(.))
```

```{r}
means_ia_geco  %>% mutate_if(is.numeric, round, digits=5)
tests_ia_geco  %>% mutate_if(is.numeric, round, digits=5)
```

L1/L2 -- GECO/CELER interaction
```{r}
combined = bind_rows(celer_ia_long, geco_ia_long)
intercation_English_dataset <-  combined %>% group_by(fix_measure) %>% do(run_lmer_geco_celer_interaction(.))
intercation_English_dataset
```

```{r}
means_celer_fix <- celer_fix_long %>% group_by(fix_measure, English) %>% do(mean_lmer(.))
tests_celer_fix <- celer_fix_long %>% group_by(fix_measure) %>% do(run_lmer(.))
```

```{r}
means_celer_fix %>% mutate_if(is.numeric, round, digits=2)
tests_celer_fix %>% mutate_if(is.numeric, round, digits=2)
```

```{r}
celer_fix <- celer_fix %>% mutate(NEXT_SAC_AMPLITUDE_c = NEXT_SAC_AMPLITUDE - mean(NEXT_SAC_AMPLITUDE))
m_velocity <- lmer(NEXT_SAC_AVG_VELOCITY ~ English_05*NEXT_SAC_AMPLITUDE_c + (1 |SUBJECT), 
                   control=lmerControl(optimizer = "bobyqa", calc.derivs = FALSE), data=celer_fix)
summary(m_velocity)$coefficients
```


========END=======

OTHER: Obtain random effects for separately for L1 and L2 in CELER and GECO

```{r, fig.height=6,fig.width=8}

get_random_effects_julia <- function(dataset, normalize = TRUE){
  print(paste(unique(dataset$DATASET), unique(dataset$English), unique(dataset$fix_measure)))
  mx_formula <- "RT ~ FREQUENCY_c + SURPRISAL_c + WORD_LEN_c + (FREQUENCY_c + SURPRISAL_c + WORD_LEN_c | SUBJECT)"
  julia_assign("dataset", dataset)
  julia_assign("formula", formula(mx_formula))
  julia_eval("m = fit(LinearMixedModel, formula, dataset)")
  rand = t(julia_eval("ranef(m)")[1])
  colnames(rand) <- c("Intercept", "FREQUENCY", "SURPRISAL", "WORD_LEN")
  fixed = t(julia_eval("coef(m)"))
  colnames(fixed) <- c("Intercept", "FREQUENCY", "SURPRISAL", "WORD_LEN")
  if (normalize == TRUE){
    rand = sweep(rand, 2, fixed, "/") #divide random effects by fixed effects
  }
  rand = data.frame(rand)
  rand <- gather(rand, "coef", "SUBJECT_COEFFICIENT", c("FREQUENCY", "SURPRISAL","WORD_LEN"))
  return(rand)
}

get_subject_effects <- function(dataset, normalize = TRUE){
    #Fit a separate model for each subject
    print(paste(unique(dataset$DATASET), unique(dataset$English), unique(dataset$fix_measure)))
    m = lmList(RT ~ FREQUENCY_c + SURPRISAL_c + WORD_LEN_c | SUBJECT, data = dataset)
    coefs = coef(m) #%>% rownames_to_column("SUBJECT")
    colnames(coefs) <- c("Intercept", "FREQUENCY", "SURPRISAL", "WORD_LEN")
    means = colMeans(coefs)
    coefs = sweep(coefs, 2, means, "-")
    if (normalize == TRUE){
      print("normalizing....")
      coefs = sweep(coefs, 2, means, "/")
    }
    coefs_long <- gather(coefs, "coef", "SUBJECT_COEFFICIENT", c("FREQUENCY", "SURPRISAL","WORD_LEN"))
    return(coefs_long)
}

plot_coefs <- function(data, bars, test){
  p <- ggplot() +
      theme_bw(base_size = 25) +
      geom_point(data = data, aes(x = coef, y = SUBJECT_COEFFICIENT, fill = DATASET), 
              pch = 21, position = position_jitterdodge(dodge.width = 1), alpha = 0.05, size = 4) + 
      #geom_boxplot(data = data, aes(x = coef, SUBJECT_COEFFICIENT, fill = DATASET), width = 0.4, outlier.size = 0) +
      geom_errorbar(data = bars, aes(x = coef, ymin = 0-std/2, ymax = 0+std/2, width = 0.3,   color = DATASET), size = 1, position = "dodge") +
      geom_text(data = test, aes(x = coef, y = Inf, label=stars), vjust=1, size = 8, color = "black") +
      facet_wrap(English ~ fix_measure, scales = "free") + theme(aspect.ratio = 0.75) +
      theme(axis.title.x=element_blank())
  return(p)
}
```

```{r,fig.height=6,fig.width=8}
normalization = TRUE

#subject_coefs <- bind_rows(geco_ia_oov_long, celer_ia_oov_long) %>% group_by(DATASET, English, fix_measure) %>% do(get_subject_effects(., normalize=normalize_coefs)) %>% ungroup()
subject_ranefs <- bind_rows(geco_ia_oov_long, celer_ia_oov_long) %>% group_by(DATASET, English, fix_measure) %>% do(get_random_effects_julia(., normalize=normalization)) %>% ungroup()
bars <- subject_ranefs %>% group_by(DATASET, English, fix_measure, coef) %>% summarise(std = sd(SUBJECT_COEFFICIENT)) %>% ungroup()
test <- subject_ranefs %>% group_by(English, fix_measure, coef) %>% 
                           summarise(levene = leveneTest(SUBJECT_COEFFICIENT ~ DATASET, center = mean)$`Pr(>F)`[1]) %>%  
                           mutate(stars = symnum(levene, corr = FALSE, na = FALSE, cutpoints = c(0,0.001,0.01,0.05,1), symbols = c("***","**","*","(.)")))
p_ranefs <- plot_coefs(subject_ranefs, bars, test)
ggsave(file=paste("dataset_analyses_figures/coefs-rand-norm_",normalization,".pdf", sep=""), height=18,width=24, p_ranefs)

print(p_ranefs)
```
